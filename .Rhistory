knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
install.packages("randomForest")
library(randomForest)
# Assuming 'y' is your response variable and 'x1', 'x2', etc., are your predictors.
model <- randomForest(avg_salary ~ job_state +excel+python_yn+R_yn +job_simp, data = data, ntree = 500)
# Assuming 'y' is your response variable and 'x1', 'x2', etc., are your predictors.
data
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
# Set the working directory to the location of the CSV file
setwd("/Users/kevinrivas/Documents/R")
# Read the CSV file
data <- read.csv("data_salarios.csv")  # Replace "filename.csv" with the actual CSV file's name
data <- subset(data, age <= 70 & age>=18)
install.packages("randomForest")
library(randomForest)
# Assuming 'y' is your response variable and 'x1', 'x2', etc., are your predictors.
model <- randomForest(avg_salary ~ job_state +excel+python_yn+R_yn +job_simp, data = data, ntree = 500)
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = new_data)
install.packages("randomForest")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
install.packages("randomForest")
library(randomForest)
# Assuming 'y' is your response variable and 'x1', 'x2', etc., are your predictors.
model <- randomForest(avg_salary ~ job_state +excel+python_yn+R_yn +job_simp, data = data, ntree = 500)
model
# Assuming 'y' is your response variable and 'x1', 'x2', etc., are your predictors.
# Assuming your data is stored in a dataframe called 'data'
set.seed(123)  # For reproducibility
# Generate random indices for splitting the data
indices <- sample(1:nrow(data), nrow(data) * 0.7)
# Create the training and testing datasets
training_data <- data[indices, ]
testing_data <- data[-indices, ]
model <- randomForest(avg_salary ~ job_state +excel+python_yn+R_yn +job_simp, data = training_data, ntree = 500)
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Evaluate classification model
confusion_matrix <- table(predictions, true_labels)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$actual_labels
confusion_matrix <- table(predictions, true_labels)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$actual_labels
confusion_matrix <- table(predictions, true_labels)
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$actual_labels
confusion_matrix <- table(predictions, true_labels)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
true_labels <- true_labels[1:100,]
predictions <- predict[1:100,]
predictions <- predict[1:100,]
predictions <- predictions[1:100,]
predictions
true_labels <- true_labels[1:80,]
predictions <- predictions[1:80,]
predictions <- predictions[1:10,]
predictions <- predictions[1:80]
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$actual_labels
true_labels80 <- true_labels[1:80,]
predictions80 <- predictions[1:80]
confusion_matrix <- table(predictions80, true_labels80)
true_label.length
true_labels.length
true_labels80.length
length(true_labels[1:80,])
length(true_labels80)
predictions80 <- predictions[1:80]
length(predictions)
true_labels80<-true_labels[1:80,]
length(true_labels80)
true_labels
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$actual_labels
true_labels
# Assuming 'y' is your response variable and 'x1', 'x2', etc., are your predictors.
# Assuming your data is stored in a dataframe called 'data'
set.seed(123)  # For reproducibility
# Generate random indices for splitting the data
indices <- sample(1:nrow(data), nrow(data) * 0.7)
# Create the training and testing datasets
training_data <- data[indices, ]
testing_data <- data[-indices, ]
model <- randomForest(avg_salary ~ job_state +excel+python_yn+R_yn +job_simp, data = training_data, ntree = 500)
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$actual_labels
true_labels
testing_data
# Create the training and testing datasets
training_data <- data[indices, ]
training_data
testing_data
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
predictions
testing_data
testing_data$actual_labels
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
testing_data
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$avg_salary
true_labels
length(predictions)
confusion_matrix <- table(predictions, true_labels)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Evaluate regression model
mae <- mean(abs(predictions - true_values))
mse <- mean((predictions - true_values)^2)
accuracy
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$avg_salary
confusion_matrix <- table(predictions, true_labels)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predictions - true_labels))
# Calculate Mean Squared Error (MSE)
mse <- mean((predictions - true_labels)^2)
# Print the results
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("Mean Squared Error (MSE):", mse, "\n")
accuracy
varImpPlot(model)
plot(model)
tree <- getTree(model, k = 1)  # Extract the first tree
plot(tree)
confusion_matrix
confusion_matrix <- table(predictions, true_labels)
confusion_matrix
model <- randomForest(job_simp ~ job_state +excel+python_yn+R_yn +avg_salary, data = training_data, ntree = 500)
model <- randomForest(job_simp ~ job_state +excel+python_yn+R_yn, data = training_data, ntree = 500)
data
model <- randomForest(job_simp ~ job_state +excel+python_yn+R_yn+avg_salary, data = training_data, ntree = 500)
model <- randomForest(as_factor(job_simp) ~ job_state +excel+python_yn+R_yn+avg_salary, data = training_data, ntree = 500)
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$avg_salary
confusion_matrix <- table(predictions, true_labels)
confusion_matrix
model <- randomForest(as_factor(job_simp) ~ job_state +excel+python_yn+R_yn+avg_salary, data = training_data, ntree = 500)
# Assuming 'new_data' is your new dataset or the testing set.
predictions <- predict(model, newdata = testing_data)
# Evaluate classification model
# Assuming 'testing_data' contains your testing dataset with true class labels in a column named 'actual_labels'
true_labels <- testing_data$job_simp
confusion_matrix <- table(predictions, true_labels)
confusion_matrix
# Instala y carga la biblioteca 'ROCR' si aún no está instalada
install.packages("ROCR")
# Instala y carga la biblioteca 'ROCR' si aún no está instalada
install.packages("ROCR")
library(ROCR)
# Crea un objeto de predicciones ROCR
prediction_obj <- prediction(predictions, true_labels)
# Crea un objeto de predicciones ROCR
prediction_obj <- prediction(predictions, true_labels)
# Crea un objeto de predicciones ROCR
prediction_obj <- prediction(predictions, true_labels)
library(ROCR)
# Crea un objeto de predicciones ROCR
prediction_obj <- prediction(predictions, true_labels)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
install.packages('datasets')
install.packages('caTools')
install.packages("datasets")
install.packages('party')
install.packages('party')
install.packages('dplyr')
install.packages('magrittr')
library(datasets)
library(caTools)
install.packages("magrittr")
install.packages("dplyr")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
install.packages('datasets')
install.packages('caTools')
install.packages('party')
install.packages("caTools")
install.packages("datasets")
install.packages('dplyr')
install.packages('magrittr')
install.packages("rpart.plot")
install.packages("randomForest")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
install.packages('datasets')
install.packages('caTools')
install.packages('party')
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
install.packages('datasets')
install.packages('caTools')
install.packages('party')
install.packages("datasets")
install.packages('dplyr')
install.packages('magrittr')
install.packages("rpart.plot")
install.packages("magrittr")
install.packages("dplyr")
install.packages("randomForest")
library(randomForest)
library(datasets)
library(caTools)
library(party)
library(dplyr)
library(magrittr)
library(rpart.plot)
sample_data = sample.split(data2, SplitRatio = 0.8)
sample_data = sample.split(data2, SplitRatio = 0.8)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(forcats)
install.packages('datasets')
install.packages('caTools')
install.packages('party')
install.packages('dplyr')
install.packages('magrittr')
install.packages("rpart.plot")
install.packages("randomForest")
library(randomForest)
library(datasets)
library(caTools)
library(party)
library(dplyr)
library(magrittr)
library(rpart.plot)
install.packages("caTools")
install.packages("party")
install.packages("dplyr")
install.packages("magrittr")
install.packages("rpart.plot")
install.packages("randomForest")
install.packages("party")
install.packages("dplyr")
install.packages("datasets")
install.packages("dplyr")
install.packages("datasets")
install.packages("party")
install.packages("datasets")
# Read the CSV file
data <- read.csv("data_salarios.csv")  # Replace "filename.csv" with the actual CSV file's name
data <- subset(data, age <= 70 & age>=18)
data2 <- read.csv("data2.csv")
sample_data = sample.split(data2, SplitRatio = 0.8)
train_data <- subset(data2, sample_data == TRUE)
test_data <- subset(data2, sample_data == FALSE)
fit <- rpart(Diabetes_binary ~. , data=train_data, method = 'class')
rpart.plot(fit)
set.seed(123)
sample_data = sample.split(data2, SplitRatio = 0.7)
train_data <- subset(data2, sample_data == TRUE)
test_data <- subset(data2, sample_data == FALSE)
fit <- rpart(Diabetes_binary ~. , data=train_data, method = 'class')
rpart.plot(fit)
predict_unseen <-predict(fit, test_data, type = 'class')
rpart.plot(fit)
table_mat <- table(test_data$Diabetes_binary, predict_unseen)
tabla_mat
table_mat
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
acurracy_Test
acuracy_Test
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test
